{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append(os.path.dirname(os.path.abspath('.')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow中自带了实现数据增强的API，主要分为四类：\n",
    "- Resizing\n",
    "- Cropping\n",
    "- Flipping and Transposing\n",
    "- Image Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.dataset import load_cifar10\n",
    "import numpy as np\n",
    "from CNN.mini_CNN import mini_CNN\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True    # 按需使用显存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备\n",
    "这里使用CIFAR-10中的三张图片，模拟训练过程中的一个batch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data = load_cifar10(batch_size=64)\n",
    "# for batch_data, _ in train_data.next_batch():\n",
    "#     img_batch = batch_data\n",
    "#     break\n",
    "# del train_data, test_data\n",
    "\n",
    "# batch_size = 5\n",
    "# img_batch = img_batch[:batch_size].reshape(\n",
    "#     (-1, 3, 32, 32)).transpose((0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "# fig, axs = plt.subplots(1, batch_size, figsize=(10, 2))\n",
    "# for i in range(batch_size):\n",
    "#     axs[i].imshow(img_batch[i])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing\n",
    "```tf.image.resize_images```同时支持batch输入与单张图片输入，有四种插值方法：BILINEAR、NEAREST_NEIGHBOR、BICUBIC和AREA，除了NEAREST_NEIGHBOR，另外三种方法都只能接受```float```格式的输入，所以为了最大兼容性，在缩放图片之前，需要将图片转换成浮点格式。同样的，标准的RBG三通道图片格式为```uint8```，所以在可视化或保存图片时还要再做转换。\n",
    "\n",
    "不过由于在```CifarData```这个类中我们使用了```MinMaxScaler```这一缩放模式，所以无需担心格式问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('img_resize'):\n",
    "#     img = tf.image.resize_images(img_batch, (48, 48), method=0)\n",
    "\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     res = sess.run(img)\n",
    "\n",
    "# plt.clf()\n",
    "# fig, axs = plt.subplots(1, batch_size, figsize=(10, 2))\n",
    "# for i in range(batch_size):\n",
    "#     axs[i].imshow(res[i])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping\n",
    "- ```tf.image.pad_to_bounding_box(image, offset_height, offset_width, target_height, target_width)```：边缘填充\n",
    "- ```tf.image.crop_to_bounding_box(image, offset_height, offset_width, target_height, target_width)```：裁剪\n",
    "- ```tf.image.random_crop(image, size, seed=None, name=None)```：随机裁剪，需指定所有维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('img_crop'):\n",
    "#     img = tf.image.random_crop(img_batch, size=(img_batch.shape[0], 25, 25, 3))\n",
    "\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     res = sess.run(img)\n",
    "\n",
    "# plt.clf()\n",
    "# fig, axs = plt.subplots(1, batch_size, figsize=(10, 2))\n",
    "# for i in range(batch_size):\n",
    "#     axs[i].imshow(res[i])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('img_crop'):\n",
    "#     img = tf.image.pad_to_bounding_box(img_batch, offset_height=2, offset_width=4,\n",
    "#                                        target_height=36, target_width=40)\n",
    "\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     res = sess.run(img)\n",
    "\n",
    "# plt.clf()\n",
    "# fig, axs = plt.subplots(1, batch_size, figsize=(10, 2))\n",
    "# for i in range(batch_size):\n",
    "#     axs[i].imshow(res[i])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flipping and Transposing\n",
    "- ```tf.image.random_flip_up_down(image)```\n",
    "- ```tf.image.random_flip_left_right(image)```\n",
    "- ```tf.image.transpose_image(image)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('img_crop'):\n",
    "#     img = tf.image.random_flip_up_down(img_batch)\n",
    "\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     res = sess.run(img)\n",
    "\n",
    "# plt.clf()\n",
    "# fig, axs = plt.subplots(1, batch_size, figsize=(10, 2))\n",
    "# for i in range(batch_size):\n",
    "#     axs[i].imshow(res[i])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjustments\n",
    "- ```tf.image.adjust_brightness(image, delta, min_value=None, max_value=None)```\n",
    "- ```tf.image.random_brightness(image, max_delta, seed=None)```\n",
    "- ```tf.image.adjust_contrast(images, contrast_factor, min_value=None, max_value=None)```\n",
    "- ```tf.image.random_contrast(image, lower, upper, seed=None)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('img_crop'):\n",
    "#     img = tf.image.random_brightness(img_batch, max_delta=0.4)\n",
    "#     img = tf.clip_by_value(img, 0, 1)\n",
    "\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     res = sess.run(img)\n",
    "\n",
    "# plt.clf()\n",
    "# fig, axs = plt.subplots(1, batch_size, figsize=(10, 2))\n",
    "# for i in range(batch_size):\n",
    "#     axs[i].imshow(res[i])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('img_crop'):\n",
    "#     img = tf.image.random_contrast(img_batch, lower=0.2,upper=1.8)\n",
    "#     img = tf.clip_by_value(img, 0, 1)\n",
    "\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     res = sess.run(img)\n",
    "\n",
    "# plt.clf()\n",
    "# fig, axs = plt.subplots(1, batch_size, figsize=(10, 2))\n",
    "# for i in range(batch_size):\n",
    "#     axs[i].imshow(res[i])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实时增强\n",
    "做数据增强有两种方法：第一种是在训练之前对所有数据做增强，相当于一次性增大了数据集的总量；另一种方法是在训练阶段进行实时增强，这里演示第二种方法。同时考虑到数据增强会使得神经网络需要更大的迭代次数去学习，这里只使用翻转。\n",
    "\n",
    "注意，数据增强应该只应用与训练集，即训练过程才需要数据增强。这需要使用TensorFlow的control flow去实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072) (50000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072) (10000,)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/hujinzhi/DL_for_learner/CNN/mini_CNN.py:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /home/hujinzhi/DL_for_learner/CNN/mini_CNN.py:10: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From /home/hujinzhi/DL_for_learner/CNN/mini_CNN.py:21: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/hujinzhi/DL_for_learner/CNN/mini_CNN.py:22: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_data, test_data = load_cifar10(batch_size=batch_size)\n",
    "\n",
    "unit_I = train_data.n_features\n",
    "X = tf.placeholder(tf.float32, [None, unit_I])\n",
    "Y = tf.placeholder(tf.int64, [None])\n",
    "X_img = tf.transpose(tf.reshape(X, [-1, 3, 32, 32]),\n",
    "                     perm=[0, 2, 3, 1])\n",
    "\n",
    "\n",
    "def data_aug(X_img):\n",
    "    '''\n",
    "    数据增强\n",
    "    X_img: 原图片张量\n",
    "    '''\n",
    "    X_img_trans = tf.image.random_flip_left_right(X_img)    # 翻转\n",
    "    return X_img_trans\n",
    "\n",
    "\n",
    "# tf.cond的pred参数不能是bool值，所以这里使用int型\n",
    "is_training = tf.placeholder(tf.int16)\n",
    "X_img_trans = tf.cond(is_training > 0, lambda: data_aug(X_img), lambda: X_img)\n",
    "\n",
    "with tf.name_scope('CNN'):\n",
    "    logits = mini_CNN(X_img_trans, activation=tf.nn.leaky_relu)\n",
    "\n",
    "with tf.name_scope('Eval'):\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=Y, logits=logits)\n",
    "    predict = tf.argmax(logits, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predict, Y), tf.float32))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    lr = 1e-3\n",
    "    train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, batch_loss: 1.5107368230819702, batch_acc: 0.375\n",
      "epoch: 2, batch_loss: 1.273892879486084, batch_acc: 0.46875\n",
      "epoch: 2, batch_loss: 1.3984922170639038, batch_acc: 0.59375\n",
      "epoch: 3, batch_loss: 0.9320375919342041, batch_acc: 0.75\n",
      "epoch: 4, batch_loss: 1.0769767761230469, batch_acc: 0.5625\n",
      "epoch: 4, test_acc: 0.651442289352417\n",
      "epoch: 4, batch_loss: 1.3465605974197388, batch_acc: 0.53125\n",
      "epoch: 5, batch_loss: 0.6441978216171265, batch_acc: 0.75\n",
      "epoch: 6, batch_loss: 1.0151033401489258, batch_acc: 0.5625\n",
      "epoch: 6, batch_loss: 0.7728836536407471, batch_acc: 0.75\n",
      "epoch: 7, batch_loss: 0.9682464003562927, batch_acc: 0.71875\n",
      "epoch: 7, test_acc: 0.6898036599159241\n",
      "epoch: 8, batch_loss: 0.6210789084434509, batch_acc: 0.75\n",
      "epoch: 8, batch_loss: 0.4844314455986023, batch_acc: 0.8125\n",
      "epoch: 9, batch_loss: 0.6945263147354126, batch_acc: 0.71875\n",
      "epoch: 9, batch_loss: 0.7143003940582275, batch_acc: 0.71875\n",
      "epoch: 10, batch_loss: 0.9262591600418091, batch_acc: 0.71875\n",
      "epoch: 10, test_acc: 0.7149438858032227\n",
      "epoch: 11, batch_loss: 0.7028826475143433, batch_acc: 0.6875\n",
      "epoch: 11, batch_loss: 0.7800813317298889, batch_acc: 0.6875\n",
      "epoch: 12, batch_loss: 0.6606230735778809, batch_acc: 0.71875\n",
      "epoch: 13, batch_loss: 0.5366835594177246, batch_acc: 0.8125\n",
      "epoch: 13, batch_loss: 0.8755141496658325, batch_acc: 0.71875\n",
      "epoch: 13, test_acc: 0.719651460647583\n",
      "epoch: 14, batch_loss: 0.9255294799804688, batch_acc: 0.625\n",
      "epoch: 15, batch_loss: 0.748676598072052, batch_acc: 0.65625\n",
      "epoch: 15, batch_loss: 0.9703848361968994, batch_acc: 0.65625\n",
      "epoch: 16, batch_loss: 0.7093278169631958, batch_acc: 0.75\n",
      "epoch: 17, batch_loss: 0.46255427598953247, batch_acc: 0.875\n",
      "epoch: 17, test_acc: 0.7333734035491943\n",
      "epoch: 17, batch_loss: 0.5862351059913635, batch_acc: 0.78125\n",
      "epoch: 18, batch_loss: 0.755439281463623, batch_acc: 0.75\n",
      "epoch: 18, batch_loss: 0.5745667219161987, batch_acc: 0.84375\n",
      "epoch: 19, batch_loss: 0.8217464089393616, batch_acc: 0.65625\n",
      "epoch: 20, batch_loss: 0.3772468566894531, batch_acc: 0.9375\n",
      "epoch: 20, test_acc: 0.7339743375778198\n",
      "epoch: 20, batch_loss: 1.2440048456192017, batch_acc: 0.6875\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    epochs = 20\n",
    "\n",
    "    batch_cnt = 0\n",
    "    for epoch in range(epochs):\n",
    "        for batch_data, batch_labels in train_data.next_batch():\n",
    "            batch_cnt += 1\n",
    "            loss_val, acc_val, _ = sess.run(\n",
    "                [loss, accuracy, train_op],\n",
    "                feed_dict={\n",
    "                    X: batch_data,\n",
    "                    Y: batch_labels,\n",
    "                    is_training:1})\n",
    "\n",
    "            # 每1000batch输出一次信息\n",
    "            if (batch_cnt+1) % 1000 == 0:\n",
    "                print('epoch: {}, batch_loss: {}, batch_acc: {}'.format(\n",
    "                    epoch+1, loss_val, acc_val))\n",
    "\n",
    "            # 每5000batch做一次验证\n",
    "            if (batch_cnt+1) % 5000 == 0:\n",
    "                all_test_acc_val = list()\n",
    "                for test_batch_data, test_batch_labels in test_data.next_batch():\n",
    "                    test_acc_val = sess.run(\n",
    "                        [accuracy],\n",
    "                        feed_dict={\n",
    "                            X: test_batch_data,\n",
    "                            Y: test_batch_labels,\n",
    "                            is_training:0\n",
    "                        })\n",
    "                    all_test_acc_val.append(test_acc_val)\n",
    "                test_acc = np.mean(all_test_acc_val)\n",
    "                print('epoch: {}, test_acc: {}'.format(epoch+1, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里仅仅只应用了左右翻转，ACC就已经有所上升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
