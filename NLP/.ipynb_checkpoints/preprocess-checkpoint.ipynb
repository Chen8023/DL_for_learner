{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import jieba\n",
    "\n",
    "# raw file\n",
    "train_file='cnews.train.txt'\n",
    "val_file='cnews.val.txt'\n",
    "test_file='cnews.test.txt'\n",
    "\n",
    "# 分词后的文件\n",
    "seg_train_file='cnews.seg_train.txt'\n",
    "seg_val_file='cnews.seg_val.txt'\n",
    "seg_test_file='cnews.seg_test.txt'\n",
    "\n",
    "# 词表\n",
    "vocal_table='cnews.vocal.txt'\n",
    "\n",
    "# 类别表\n",
    "cat_file='cnews.cat.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.796 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "def gen_seg_file(file_in, file_out):\n",
    "    with open(file_in, 'r', encoding='utf-8') as fd:\n",
    "        text = fd.readlines()\n",
    "    with open(file_out, 'w', encoding='utf-8') as fd:\n",
    "        for line in text:\n",
    "            _, data = line.strip().split('\\t')\n",
    "            words = jieba.cut(data)\n",
    "            words_trans = ''\n",
    "\n",
    "            # 去除切分出来的空白词\n",
    "            for word in words:\n",
    "                word = word.strip()\n",
    "                if word != '':\n",
    "                    words_trans += word+' '\n",
    "\n",
    "            out_line = '{}\\t{}\\n'.format(label, words_trans.strip())\n",
    "            fd.write(out_line)\n",
    "\n",
    "\n",
    "gen_seg_file(train_file, seg_train_file)\n",
    "gen_seg_file(val_file, seg_val_file)\n",
    "gen_seg_file(test_file, seg_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词典映射表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tabel(file_in, file_out):\n",
    "    with open(file_in, 'r', encoding='utf-8') as fd:\n",
    "        text = fd.readlines()\n",
    "\n",
    "    word_dict = dict()\n",
    "    for line in text:\n",
    "        _, data = line.strip().split('\\t')\n",
    "        for word in data.split():\n",
    "            word_dict.setdefault(word, 0)\n",
    "            word_dict[word] += 1\n",
    "    word_dict = sorted(word_dict.items(), key=lambda x: x[1],\n",
    "                       reverse=True)\n",
    "\n",
    "    with open(file_out, 'w', encoding='utf-8') as fd:\n",
    "        fd.write('0,<UNK>,99999\\n')\n",
    "        for idx, item in enumerate(word_dict):\n",
    "            fd.write('{},{},{}\\n'.format(idx+1, item[0], item[1]))\n",
    "\n",
    "\n",
    "gen_tabel(seg_train_file, vocal_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成类别文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_cat(file_in,file_out):\n",
    "    with open(file_in, 'r', encoding='utf-8') as fd:\n",
    "        text = fd.readlines()\n",
    "        \n",
    "    label_dict = dict()\n",
    "    for line in text:\n",
    "        label, _ = line.strip().split('\\t')\n",
    "        label_dict.setdefault(label, 0)\n",
    "        label_dict[label] += 1\n",
    "    label_dict = sorted(label_dict.items(), key=lambda x: x[1],\n",
    "                       reverse=True)\n",
    "    \n",
    "    with open(file_out,'w',encoding='utf-8') as fd:\n",
    "        for idx,item in enumerate(label_dict):\n",
    "            fd.write('{},{},{}\\n'.format(idx,item[0],item[1]))\n",
    "            \n",
    "gen_cat(train_file,cat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
